[toc]




# 4. 调度时机

> 本章主要讨论何时发生调度

一般来说有三种情况

1. goroutine执行某个操作因条件不满足需要等待而发生调度
2. goroutine主动调用gosched函数让出cpu而发生的调度
3. goroutine运行时间太长或长时间处于系统调用中，而被调度器强制调度

这三种情况我们会分别来看

## 1.被动调度

### 发生调度

我们首先来看因条件不满足而等待的调度，

这个由gopark完成，

```go
// Puts the current goroutine into a waiting state and calls unlockf.
// If unlockf returns false, the goroutine is resumed.
// unlockf must not access this G's stack, as it may be moved between
// the call to gopark and the call to unlockf.
// Reason explains why the goroutine has been parked.
// It is displayed in stack traces and heap dumps.
// Reasons should be unique and descriptive.
// Do not re-use reasons, add new ones.
func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) {
	if reason != waitReasonSleep {
		checkTimeouts() // timeouts may expire while two goroutines keep the scheduler busy
	}
	mp := acquirem()
	gp := mp.curg
	status := readgstatus(gp) // 被park的G必须是 running状态
	if status != _Grunning && status != _Gscanrunning {
		throw("gopark: bad g status")
	}
	mp.waitlock = lock
	mp.waitunlockf = unlockf
	gp.waitreason = reason
	mp.waittraceev = traceEv
	mp.waittraceskip = traceskip
	releasem(mp) // drop
	// can't do anything that might move the G between Ms here.
	mcall(park_m) // 调用park_m
}
```

`gopark` 主要的工作是调用mcall(park_m),其次在前面做一些检测工作，park_m的话则完成则塞调度

```go
// park continuation on g0.
func park_m(gp *g) {
	_g_ := getg()

	if trace.enabled {
		traceGoPark(_g_.m.waittraceev, _g_.m.waittraceskip)
	}

	casgstatus(gp, _Grunning, _Gwaiting)
	dropg() // 

	if fn := _g_.m.waitunlockf; fn != nil {
		ok := fn(gp, _g_.m.waitlock)
		_g_.m.waitunlockf = nil
		_g_.m.waitlock = nil
		if !ok {
			if trace.enabled {
				traceGoUnpark(gp, 2)
			}
			casgstatus(gp, _Gwaiting, _Grunnable)
			execute(gp, true) // Schedule it back, never returns.
		}
	}
	schedule()
}
```

park_m 首先把状态切换到waiting，然后调用dropg把它跟m解绑，

然后判断是否需要做unlock操作，如果解锁失败则恢复执行。

如果不需要做unlock，那么调用schedule继续调度。

到现在，我们完成了被动调度，这个G已经被搁置起来了，我们可以去执行其他schedule了。（schedule是永远不返回的，思考下前面的[调度策略](#神奇的调度循环)）

> 笔者第一次看到这里的时候，还有一个疑惑就是这个g没了啊，没有人管它了，那么它怎么恢复呢。
>
> 继续看

### 等待唤醒

所有的`G`在自我'终结'已经完成了后事交代，以`chanrecv`为例,当没有数据的时候，会调用gopark，那么在调用之前它做了什么呢

```go
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {
	...
	// No stack splits between assigning elem and enqueuing mysg
	// on gp.waiting where copystack can find it.
	mysg.elem = ep
	mysg.waitlink = nil
	gp.waiting = mysg
	mysg.g = gp
	mysg.isSelect = false
	mysg.c = c
	gp.param = nil
	c.recvq.enqueue(mysg)
	goparkunlock(&c.lock, waitReasonChanReceive, traceEvGoBlockRecv, 3)
	...
}
```

可以看到，gp把自己包装成一个sudog[^4.1]，放进了一个队列里`c.recvq.enqueue(mysg)`，那么这个有什么用呢，我们来以`chansend`为例，看下进程的唤醒。

```go
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {
  ...
	if sg := c.recvq.dequeue(); sg != nil {
		// Found a waiting receiver. We pass the value we want to send
		// directly to the receiver, bypassing the channel buffer (if any).
		send(c, sg, ep, func() { unlock(&c.lock) }, 3)
		return true
	}
  ...
}
```

还记得上面我们enqueue了一个sudog吧，那现在队列不为空，直接走send

```go
// send processes a send operation on an empty channel c.
// The value ep sent by the sender is copied to the receiver sg.
// The receiver is then woken up to go on its merry way.
// Channel c must be empty and locked.  send unlocks c with unlockf.
// sg must already be dequeued from c.
// ep must be non-nil and point to the heap or the caller's stack.
func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) {
	... 
	if sg.elem != nil {
		sendDirect(c.elemtype, sg, ep)
		sg.elem = nil
	}
	gp := sg.g // 啊啊哈哈，这个g被取出来了。
	unlockf()
	gp.param = unsafe.Pointer(sg)
	if sg.releasetime != 0 {
		sg.releasetime = cputicks()
	}
	goready(gp, skip+1)
}
```

可见到这里我们已经取得上刚才比较迷惑的g了，那么剩下来的就是怎么把这个调度起来的问题了,这个交给我们个goready

```go
func goready(gp *g, traceskip int) {
	systemstack(func() {
		ready(gp, traceskip, true)
	})
}

// Mark gp ready to run.
func ready(gp *g, traceskip int, next bool) {
	if trace.enabled {
		traceGoUnpark(gp, traceskip)
	}

	status := readgstatus(gp)

	// Mark runnable.
	_g_ := getg()
	mp := acquirem() // disable preemption because it can be holding p in a local var
	if status&^_Gscan != _Gwaiting {
		dumpgstatus(gp)
		throw("bad g->status in ready")
	}

	// status is Gwaiting or Gscanwaiting, make Grunnable and put on runq
	casgstatus(gp, _Gwaiting, _Grunnable)
	runqput(_g_.m.p.ptr(), gp, next) // put
	if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 {
		wakep()
	}
	releasem(mp)
}
```

这里主要做的事情就是

1. 切换到g0栈
2. 把gp切换到runnable
3. 把gp放到待运行队列里，over。且next为true,高优先级！！！
4. 剩下的就交给我们的调度了，gp总会被调度起来的

> 关于runqput暂时不详细分析，它大概的策略就是放到本地队列，如果满了就放到全局队列
>
> ```
> // runqput tries to put g on the local runnable queue.
> // If next is false, runqput adds g to the tail of the runnable queue.
> // If next is true, runqput puts g in the _p_.runnext slot.
> // If the run queue is full, runnext puts g on the global queue.
> // Executed only by the owner P.
> ```

### 可能发生被动调度的地方

按照刚才的理解的话，所有的被动调度都会调用gopark，那我们看下当前的情况。

![image-20200531183142249](http://picgo.vipkk.work/20200531183142.png)

一共有13处，我们依次看下

1. chansend & chanrecv

   这个就是我们刚刚分析的 channel阻塞的时候

2. lock_js.go中的3~7，不懂跳过

3. mgc.go:gcBgMarkWorker

   这个是在gc时候标记准备阶段，stw(如有不对，请拍砖，笔者暂时还没有详细看GC源码)

4. `netpoll.go:netpollblock`

   这是在等待网络io的时候的阻塞，

   > netpoll 是go在epoll基础上封装的网络io库，轻量好用！！！

5. `proc.go:main` pass

6. `proc.go:goparkunlock` 

   一个封装，也是channel重视会用

7. `select.go:block`  & `select.go:selectgo` 

   go select函数阻塞。

### 开始唤醒

我们前面已经把`g`唤醒了，但是一个g要运行还需要`p`和`m`。那么我们开始吧

#### 唤醒空闲的P

```go
    if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 {
        //有空闲的p而且没有正在偷取goroutine的工作线程，则需要唤醒p出来工作
        wakep()
    }
```

在唤醒g之后，如果当前有空闲的g`atomic.Load(&sched.npidle) != 0`,并且没有处于spinning的工作线程的话`atomic.Load(&sched.nmspinning) == 0`，那么就去唤醒p`wakep`来工作。

> Q:为什么需要没有spinning的工作线程
>
> A:因为处于spinning的工作线程本身就在执行偷取工作了，没必要在唤醒一个新的出来了。（这个时候是空余的）

具体的操作由wakep去唤醒

```go
// Tries to add one more P to execute G's.
// Called when a G is made runnable (newproc, ready).
func wakep() {
	// be conservative about spinning threads
	if !atomic.Cas(&sched.nmspinning, 0, 1) {
		return
	}
	startm(nil, true)
}
```

wakep再次确认了是否有spinning线程，如果没有的话就去寻找一个m来工作了。

```go
// Schedules some M to run the p (creates an M if necessary).
// If p==nil, tries to get an idle P, if no idle P's does nothing.
// May run with m.p==nil, so write barriers are not allowed.
// If spinning is set, the caller has incremented nmspinning and startm will
// either decrement nmspinning or set m.spinning in the newly started M.
//go:nowritebarrierrec
func startm(_p_ *p, spinning bool) {
    lock(&sched.lock)
    if _p_ == nil { //没有指定p的话需要从p的空闲队列中获取一个p
        _p_ = pidleget() //从p的空闲队列中获取空闲p
        if _p_ == nil {
            unlock(&sched.lock)
            if spinning {
                // The caller incremented nmspinning, but there are no idle Ps,
                // so it's okay to just undo the increment and give up.
                //spinning为true表示进入这个函数之前已经对sched.nmspinning加了1，需要还原
                if int32(atomic.Xadd(&sched.nmspinning, -1)) < 0 {
                    throw("startm: negative nmspinning")
                }
            }
            return //没有空闲的p，直接返回
        }
    }
    mp := mget() //从m空闲队列中获取正处于睡眠之中的工作线程，所有处于睡眠状态的m都在此队列中
    unlock(&sched.lock)
    if mp == nil {
        //没有处于睡眠状态的工作线程
        var fn func()
        if spinning {
            // The caller incremented nmspinning, so set m.spinning in the new M.
            fn = mspinning
        }
        newm(fn, _p_) //创建新的工作线程
        return
    }
    if mp.spinning {
        throw("startm: m is spinning")
    }
    if mp.nextp != 0 {
        throw("startm: m has p")
    }
    if spinning && !runqempty(_p_) {
        throw("startm: p has runnable gs")
    }
    // The caller incremented nmspinning, so set m.spinning in the new M.
    mp.spinning = spinning
    mp.nextp.set(_p_)
   
    //唤醒处于休眠状态的工作线程
    notewakeup(&mp.park)
}
```

startm用来负责唤醒或创建m，

首先它判断当前有没有空余的p，没有则返回。

然后尝试获取一个m，如果可以获取到，那么就去唤醒他，

如果获取不到，那么就去创建一个。

#### 唤醒M

唤醒是通过`notewakeup`实现的，note我们前面讲过他的封装机制，底层是对os的一些操作。

```go
func notewakeup(n *note) {
    //设置n.key = 1, 被唤醒的线程通过查看该值是否等于1来确定是被其它线程唤醒还是意外从睡眠中苏醒
    old := atomic.Xchg(key32(&n.key), 1)  
    if old != 0 {
        print("notewakeup - double wakeup (", old, ")\n")
        throw("notewakeup - double wakeup")
    }
    //调用futexwakeup唤醒
    futexwakeup(key32(&n.key), 1)
}
```

设置唤醒key,然后调用futexwakeup

```golang
// If any procs are sleeping on addr, wake up at most cnt.
//go:nosplit
func futexwakeup(addr *uint32, cnt uint32) {
    //调用futex函数唤醒工作线程
    ret := futex(unsafe.Pointer(addr), _FUTEX_WAKE_PRIVATE, cnt, nil, nil, 0)
    if ret >= 0 {
        return
    }

    // I don't know that futex wakeup can return
    // EAGAIN or EINTR, but if it does, it would be
    // safe to loop and call futex again.
    systemstack(func() {
        print("futexwakeup addr=", addr, " returned ", ret, "\n")
    })

    *(*int32)(unsafe.Pointer(uintptr(0x1006))) = 0x1006
}
```

对于Linux平台来说，工作线程通过note睡眠其实是通过futex系统调用睡眠在内核之中，所以唤醒处于睡眠状态的线程也需要通过futex系统调用进入内核来唤醒，所以这里的futexwakeup又继续调用包装了futex系统调用的futex函数来实现唤醒睡眠在内核中的工作线程。由 futex 完成最终的调用。



#### 创建M

由`newm`开始

```go
// Create a new m. It will start off with a call to fn, or else the scheduler.
// fn needs to be static and not a heap allocated closure.
// May run with m.p==nil, so write barriers are not allowed.
//go:nowritebarrierrec
func newm(fn func(), _p_ *p) {
    mp := allocm(_p_, fn)
    mp.nextp.set(_p_)
    ......
    newm1(mp)
}
```

newm首先调用allocm函数从堆上分配一个m结构体对象，然后调用newm1函数。

```go
func newm1(mp *m) {
      //省略cgo相关代码.......
      execLock.rlock() // Prevent process clone.
      newosproc(mp)
      execLock.runlock()
}
```

newm1继续调用newosproc函数，newosproc的主要任务是调用clone函数创建一个系统线程，而新建的这个系统线程将从mstart函数开始运行。

```go
// May run with m.p==nil, so write barriers are not allowed.
//go:nowritebarrier
func newosproc(mp *m) {
    stk := unsafe.Pointer(mp.g0.stack.hi)                    
    ......
    ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0),         unsafe.Pointer(funcPC(mstart)))
    ......
}

//clone系统调用的Flags选项
cloneFlags = _CLONE_VM | /* share memory */ //指定父子线程共享进程地址空间
  _CLONE_FS | /* share cwd, etc */
  _CLONE_FILES | /* share fd table */
  _CLONE_SIGHAND | /* share sig handler table */
  _CLONE_SYSVSEM | /* share SysV semaphore undo lists (see issue #20763) */
  _CLONE_THREAD /* revisit - okay for now */  //创建子线程而不是子进程
```

clone 可以参考类比fork,由汇编实现，完成工作线程的创建

```assembly
// int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
TEXT runtime·clone(SB),NOSPLIT,$0
	MOVL	flags+0(FP), DI // 以下4个是系统调用的参数 flags第一个参数，代表创建选项
	MOVQ	stk+8(FP), SI // stk := unsafe.Pointer(mp.g0.stack.hi), 是栈的位置
	MOVQ	$0, DX
	MOVQ	$0, R10

	// Copy mp, gp, fn off parent stack for use by child.
	// Careful: Linux system call clobbers CX and R11.
	MOVQ	mp+16(FP), R8 // M  新创建的M，这个就是要与OS绑定的那个M
	MOVQ	gp+24(FP), R9 // G  M要运行的g,一般是g0
	MOVQ	fn+32(FP), R12 // fn 需要执行的参数

	MOVL	$SYS_clone, AX
	SYSCALL // 执行 clone

	// In parent, return.
	CMPQ	AX, $0 // 父进程 return
	JEQ	3(PC)
	MOVL	AX, ret+40(FP)
	RET

	// In child, on new stack.
	MOVQ	SI, SP // 设置栈顶

	// If g or m are nil, skip Go-related setup.
	CMPQ	R8, $0    // m
	JEQ	nog
	CMPQ	R9, $0    // g
	JEQ	nog

	// Initialize m->procid to Linux tid
	MOVL	$SYS_gettid, AX
	SYSCALL
	MOVQ	AX, m_procid(R8) // 获取pid 并设置到m.procid

	// Set FS to point at m->tls.
	LEAQ	m_tls(R8), DI // 线程的本地存储 DI = M
	CALL	runtime·settls(SB) 

	// In child, set up new stack
	get_tls(CX)
	MOVQ	R8, g_m(R9) // 设置m
	MOVQ	R9, g(CX) // g
	CALL	runtime·stackcheck(SB)

nog:
	// Call fn
	CALL	R12 // fn 此时是mstart

	// It shouldn't return. If it does, exit that thread.
	MOVL	$111, DI
	MOVL	$SYS_exit, AX
	SYSCALL
	JMP	-3(PC)	// keep exiting
```

大概的操作做了注释，有几点需要注意的

1. os做clone操作的时候，寄存器的值也会随之clone一份，所以就有了我们在刚开始，把 g m fn放到寄存器上的操作
2. 为什么需要把g m fn呢，原因在于这几个参数目前还位于父线程的栈之中，而一旦通过系统调用把子线程创建出来之后，子线程将会使用我们在clone系统调用时给它指定的栈。 （**栈是新的**）

至此，被动调度完成，我们可以看到，被动调度的时，在我们有G运行的时候，会竭尽所能创建 PM来工作

> 引申
>
> 工作上遇到一个debug 出现异常的问题，盲猜就是创建了过多的m导致error。
>
> 待测试。
>
> gdb



## 2.主动调度

这个没什么好说的，就是代码调用`runtime.Gosched()`完成的自我放弃运行权的事情。

大体过程和之前相似不具体表述



## 3. 抢占调度

> - 什么情况下会发生抢占调度
> - 抢占调度有什么特点

之前我们说过在启动的时候会启动`sysmon`函数监控整体情况，而每次sysmon执行中都会通过`retake`函数对超过10ms的goroutine发起抢占。

发起抢占的时候有2种情况，

- 当前执行业务逻辑 _Prunning
- 当前正在系统调用 _Psyscall

首先我们先看下业务逻辑这块

### 发起抢占

具体如下

```go
// forcePreemptNS is the time slice given to a G before it is
// preempted.
const forcePreemptNS = 10 * 1000 * 1000 // 10ms

// 抢占调度检测
func retake(now int64) uint32 {
	n := 0
	// Prevent allp slice changes. This lock will be completely
	// uncontended unless we're already stopping the world.
	lock(&allpLock)
	// We can't use a range loop over allp because we may
	// temporarily drop the allpLock. Hence, we need to re-fetch
	// allp each time around the loop.
	for i := 0; i < len(allp); i++ {
		_p_ := allp[i]
		if _p_ == nil {
			// This can happen if procresize has grown
			// allp but not yet created new Ps.
			continue
		}
		pd := &_p_.sysmontick // last tick observed by sysmon
		s := _p_.status
		sysretake := false
		if s == _Prunning || s == _Psyscall {
			// Preempt G if it's running for too long.
			t := int64(_p_.schedtick) // schedtick 调度循环次数，每次调度循环完成+1
			if int64(pd.schedtick) != t { // 如果已经切换，那就更新上次调度的数
				pd.schedtick = uint32(t)
				pd.schedwhen = now
			} else if pd.schedwhen+forcePreemptNS <= now { // 如果超过规定时间
				// 抢占调度
				preemptone(_p_)
				// In case of syscall, preemptone() doesn't
				// work, because there is no M wired to P.
				sysretake = true
			}
		}
		if s == _Psyscall {
    	.... // 系统调用抢占代码
    }
	}
	unlock(&allpLock)
	return uint32(n)
}
```

由上可见，如果当前G运行时间过长（通过p上的pd判断）,那么就发起抢占 `preemptone(_p_)`

而神奇的preemptone宛如一个彬彬有礼的绅士，没坐任何暴力行为

```go
// Tell the goroutine running on processor P to stop.
// This function is purely best-effort. It can incorrectly fail to inform the
// goroutine. It can send inform the wrong goroutine. Even if it informs the
// correct goroutine, that goroutine might ignore the request if it is
// simultaneously executing newstack.
// No lock needs to be held.
// Returns true if preemption request was issued.
// The actual preemption will happen at some point in the future
// and will be indicated by the gp->status no longer being
// Grunning
func preemptone(_p_ *p) bool {
	mp := _p_.m.ptr()
	if mp == nil || mp == getg().m {
		return false
	}
	gp := mp.curg
	if gp == nil || gp == mp.g0 {
		return false
	}

	// 设置抢占调度位 为true 
	gp.preempt = true

	// Every call in a go routine checks for stack overflow by
	// comparing the current stack pointer to gp->stackguard0.
	// Setting gp->stackguard0 to StackPreempt folds
	// preemption into the normal stack overflow check.
	gp.stackguard0 = stackPreempt // 设置stackguard0为一个特别大的数

	... // 信号抢占，暂时忽略

	return true
}
```

到目前为止，负责抢占调度的retake已经完事收工，但是我们没有看到任何暴力行为，只是告诉g你需要让位了。（ps.这也就是我们称为协作式调度的原因）

### 响应抢占

这个是由newstack完成的

> 具体调度流`morestack_noctxt()->morestack()->newstack()` ,

```go
// Called from runtime·morestack when more stack is needed.
// Allocate larger stack and relocate to new stack.
// Stack growth is multiplicative, for constant amortized cost.
//
// g->atomicstatus will be Grunning or Gscanrunning upon entry.
// If the GC is trying to stop this g then it will set preemptscan to true.
//
// This must be nowritebarrierrec because it can be called as part of
// stack growth from other nowritebarrierrec functions, but the
// compiler doesn't check this.
//
//go:nowritebarrierrec
func newstack() {
    thisg := getg() // thisg = g0
    ......
    // 这行代码获取g0.m.curg，也就是需要扩栈或响应抢占的goroutine
    // 对于我们这个例子gp = main goroutine
    gp := thisg.m.curg
    ......
    // NOTE: stackguard0 may change underfoot, if another thread
    // is about to try to preempt gp. Read it just once and use that same
    // value now and below.
    //检查g.stackguard0是否被设置为stackPreempt
    preempt := atomic.Loaduintptr(&gp.stackguard0) == stackPreempt

    // Be conservative about where we preempt.
    // We are interested in preempting user Go code, not runtime code.
    // If we're holding locks, mallocing, or preemption is disabled, don't
    // preempt.
    // This check is very early in newstack so that even the status change
    // from Grunning to Gwaiting and back doesn't happen in this case.
    // That status change by itself can be viewed as a small preemption,
    // because the GC might change Gwaiting to Gscanwaiting, and then
    // this goroutine has to wait for the GC to finish before continuing.
    // If the GC is in some way dependent on this goroutine (for example,
    // it needs a lock held by the goroutine), that small preemption turns
    // into a real deadlock.
    if preempt {
        //检查被抢占goroutine的状态
        if thisg.m.locks != 0 || thisg.m.mallocing != 0 || thisg.m.preemptoff != "" ||  thisg.m.p.ptr().status != _Prunning {
            // Let the goroutine keep running for now.
            // gp->preempt is set, so it will be preempted next time.
            //还原stackguard0为正常值，表示我们已经处理过抢占请求了
            gp.stackguard0 = gp.stack.lo + _StackGuard
           
            //不抢占，调用gogo继续运行当前这个g，不需要调用schedule函数去挑选另一个goroutine
            gogo(&gp.sched) // never return
        }
    }

    //省略的代码做了些其它检查所以这里才有两个同样的判断

    if preempt {
        if gp == thisg.m.g0 {
            throw("runtime: preempt g0")
        }
        if thisg.m.p == 0 && thisg.m.locks == 0 {
            throw("runtime: g is running but p is not")
        }
        ......
        //下面开始响应抢占请求
        // Act like goroutine called runtime.Gosched.
        //设置gp的状态，省略的代码在处理gc时把gp的状态修改成了_Gwaiting
        casgstatus(gp, _Gwaiting, _Grunning)
       
        //调用gopreempt_m把gp切换出去
        gopreempt_m(gp) // never return
    }
    ......
}


func gopreempt_m(gp *g) {
	if trace.enabled {
		traceGoPreempt()
	}
	goschedImpl(gp)
}


```

可见这里我们判断如果需要抢占，那么就切换状态为调用 goschedimpl完成调度。



#### 响应抢占的细节之栈扩容

我们上面看到，响应抢占是在检查栈的时候才判断调度，那么我们就会有个疑问，什么时候检查栈

go设计：在函数调用的时候会插入栈扩容的检查代码

以以下代码为例

```go
package main

import "fmt"

func sum(a, b int) int {
    a2 := a * a
    b2 := b * b
    c := a2 + b2

    fmt.Println(c)

    return c
}

func main() {
    sum(1, 2)
}
```



运行以下命令进入gdb,结果如下

```
go build -o q3 q3.go
gdb q3
b q3.go:15
r
disass
```

<img src="/Users/gaoke/Library/Application Support/typora-user-images/image-20200607190207907.png" alt="image-20200607190207907" style="zoom:90%;" />



可见函数尾部对`morestack_noctxt`进行了调用，而跳转到该函数的逻辑是

```assembly
=> 0x0000000000490eb0 <+0>:	mov    %fs:0xfffffffffffffff8,%rcx #main函数第一条指令，rcx = g
   0x0000000000490eb9 <+9>:	cmp    0x10(%rcx),%rsp  #0x10(%rcx) 为 g.stackguard0
   0x0000000000490ebd <+13>:	jbe    0x490eed <main.main+61>
```

我们知道g结构便宜16个字节为stackguard0。那么第二行的意思就是在比较栈顶寄存器rsp的值是否比stackguard0的值小，如果rsp的值更小，说明当前g的栈要用完了，有溢出风险，需要扩栈。

回忆下栈结构

<img src="http://picgo.vipkk.work/20200607190850.png" alt="image-20200607190850026" style="zoom:50%;" />



其中正常情况下 stackguard0 = lo+stackguard,而lo有所栈底，所以这里如果rsp比 stackguard0小的话，那就需要进行扩容。在设置了抢占调度的时候，那么stackguard0 是一个特别大的值，rsp必小，所以就会进行调用morestack_noctxt。

当执行完之后，那么就继续调用main恢复执行！！！





那么在协作式调度的时候，如果一个函数里没有函数调用，那么它也就永远不会被抢占，因为我们上面分析了，`morestack_noctxt`是插在函数序言里的，如果没有的话，那就永远不会检查抢占了。

> 如果没有函数调用，那就永远阻塞了



### 对系统调用过长发起抢占

回到`retake`

```go
// 抢占调度检测
func retake(now int64) uint32 {
		...
  
 if s == _Psyscall { // 如果是系统调用的话
			// Retake P from syscall if it's there for more than 1 sysmon tick (at least 20us).
			t := int64(_p_.syscalltick)
			if !sysretake && int64(pd.syscalltick) != t {
				pd.syscalltick = uint32(t)
				pd.syscallwhen = now
				continue
			}
			// On the one hand we don't want to retake Ps if there is no other work to do,
			// but on the other hand we want to retake them eventually
			// because they can prevent the sysmon thread from deep sleep.
			if runqempty(_p_) && atomic.Load(&sched.nmspinning)+atomic.Load(&sched.npidle) > 0 && pd.syscallwhen+10*1000*1000 > now {
				/**
				进入条件
				1. 当前为空
				2. 有空闲的p （有人工作 抢占调度没必要）
				3. 未超过10ms
				 */
				continue
			}
			// Drop allpLock so we can take sched.lock.
			unlock(&allpLock)
			// Need to decrement number of idle locked M's
			// (pretending that one more is running) before the CAS.
			// Otherwise the M from which we retake can exit the syscall,
			// increment nmidle and report deadlock.
			incidlelocked(-1)
			if atomic.Cas(&_p_.status, s, _Pidle) {
				if trace.enabled {
					traceGoSysBlock(_p_)
					traceProcStop(_p_)
				}
				n++
				_p_.syscalltick++
				handoffp(_p_) // 寻找下一个新的m来让p操作
			}
			incidlelocked(1)
			lock(&allpLock)
		}
	
  ...
}
```

根据retake函数的代码，只要满足下面三个条件中的任意一个就需要对处于_Psyscall 状态的p进行抢占：

1. p的运行队列里面有等待运行的goroutine。这用来保证当前p的本地运行队列中的goroutine得到及时的调度，因为该p对应的工作线程正处于系统调用之中，无法调度队列中goroutine，所以需要寻找另外一个工作线程来接管这个p从而达到调度这些goroutine的目的；
2. 没有空闲的p。表示其它所有的p都已经与工作线程绑定且正忙于执行go代码，这说明系统比较繁忙，所以需要抢占当前正处于系统调用之中而实际上系统调用并不需要的这个p并把它分配给其它工作线程去调度其它goroutine。
3. 从上一次监控线程观察到p对应的m处于系统调用之中到现在已经超过10了毫秒。这表示只要系统调用超时，就对其抢占，而不管是否真的有goroutine需要调度，这样保证sysmon线程不至于觉得无事可做（sysmon线程会判断retake函数的返回值，如果为0，表示retake并未做任何抢占，所以会觉得没啥事情做）而休眠太长时间最终会降低sysmon监控的实时性。

综上，系统调用因为深陷在os中，go runtime鞭长莫及，所以在设置了抢占位之后，p还做了另外一件事，就是寻找下一个新的m来和p合作，脱离之前的m。

```go
/ Hands off P from syscall or locked M.
// Always runs without a P, so write barriers are not allowed.
//go:nowritebarrierrec
func handoffp(_p_ *p) {
    // handoffp must start an M in any situation where
    // findrunnable would return a G to run on _p_.

    // if it has local work, start it straight away
    //运行队列不为空，需要启动m来接管
    if !runqempty(_p_) || sched.runqsize != 0 {
        startm(_p_, false)
        return
    }
    // if it has GC work, start it straight away
    //有垃圾回收工作需要做，也需要启动m来接管
    if gcBlackenEnabled != 0 && gcMarkWorkAvailable(_p_) {
        startm(_p_, false)
        return
    }
    // no local work, check that there are no spinning/idle M's,
    // otherwise our help is not required
    //所有其它p都在运行goroutine，说明系统比较忙，需要启动m
    if atomic.Load(&sched.nmspinning)+atomic.Load(&sched.npidle) == 0 &&  atomic.Cas(&sched.nmspinning, 0, 1) { // TODO: fast atomic
        startm(_p_, true)
        return
    }
    lock(&sched.lock)
    if sched.gcwaiting != 0 { //如果gc正在等待Stop The World
        _p_.status = _Pgcstop
        sched.stopwait--
        if sched.stopwait == 0 {
            notewakeup(&sched.stopnote)
        }
        unlock(&sched.lock)
        return
    }
    ......
    if sched.runqsize != 0 { //全局运行队列有工作要做
        unlock(&sched.lock)
        startm(_p_, false)
        return
    }
    // If this is the last running P and nobody is polling network,
    // need to wakeup another M to poll network.
    //不能让所有的p都空闲下来，因为需要监控网络连接读写事件
    if sched.npidle == uint32(gomaxprocs-1) && atomic.Load64(&sched.lastpoll) != 0 {
        unlock(&sched.lock)
        startm(_p_, false)
        return
    }
    pidleput(_p_)  //无事可做，把p放入全局空闲队列
    unlock(&sched.lock)
}
```

handoffp函数流程比较简单，它的主要任务是通过各种条件判断是否需要启动工作线程来接管_p_，如果不需要则把_p_放入P的全局空闲队列。

从handoffp的代码可以看出，在如下几种情况下则需要调用我们已经分析过的startm函数启动新的工作线程出来接管_p_：

1. _p_的本地运行队列或全局运行队列里面有待运行的goroutine；
2. 需要帮助gc完成标记工作；
3. 系统比较忙，所有其它_p_都在运行goroutine，需要帮忙；
4. 所有其它P都已经处于空闲状态，如果需要监控网络连接读写事件，则需要启动新的m来poll网络连接。

到此，sysmon监控线程对处于系统调用之中的p的抢占就已经完成。



#### 系统调用

TODO

> 简单说
>
> 1. 解绑
> 2. 恢复的时候尝试重新绑定，绑定不上就去找新的。



### 信号抢占

1. https://go-review.googlesource.com/c/go/+/201762



# 参考索引

1. [ABA问题](# CAS操作和ABA问题)
2. https://mp.weixin.qq.com/s/YPiYNPa3xVD9Il1HeB5pTw











[ABA]: https://en.wikipedia.org/wiki/ABA_problem	"ABA问题"



[^4.1]: channel 用来调度g的结构