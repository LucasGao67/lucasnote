




# 4. 调度时机

> 本章主要讨论何时发生调度

一般来说有三种情况

1. goroutine执行某个操作因条件不满足需要等待而发生调度
2. goroutine主动调用gosched函数让出cpu而发生的调度
3. goroutine运行时间太长或长时间处于系统调用中，而被调度器强制调度

这三种情况我们会分别来看

## 1.被动调度

### 发生调度

我们首先来看因条件不满足而等待的调度，

这个由gopark完成，

```go
// Puts the current goroutine into a waiting state and calls unlockf.
// If unlockf returns false, the goroutine is resumed.
// unlockf must not access this G's stack, as it may be moved between
// the call to gopark and the call to unlockf.
// Reason explains why the goroutine has been parked.
// It is displayed in stack traces and heap dumps.
// Reasons should be unique and descriptive.
// Do not re-use reasons, add new ones.
func gopark(unlockf func(*g, unsafe.Pointer) bool, lock unsafe.Pointer, reason waitReason, traceEv byte, traceskip int) {
	if reason != waitReasonSleep {
		checkTimeouts() // timeouts may expire while two goroutines keep the scheduler busy
	}
	mp := acquirem()
	gp := mp.curg
	status := readgstatus(gp) // 被park的G必须是 running状态
	if status != _Grunning && status != _Gscanrunning {
		throw("gopark: bad g status")
	}
	mp.waitlock = lock
	mp.waitunlockf = unlockf
	gp.waitreason = reason
	mp.waittraceev = traceEv
	mp.waittraceskip = traceskip
	releasem(mp) // drop
	// can't do anything that might move the G between Ms here.
	mcall(park_m) // 调用park_m
}
```

`gopark` 主要的工作是调用mcall(park_m),其次在前面做一些检测工作，park_m的话则完成则塞调度

```go
// park continuation on g0.
func park_m(gp *g) {
	_g_ := getg()

	if trace.enabled {
		traceGoPark(_g_.m.waittraceev, _g_.m.waittraceskip)
	}

	casgstatus(gp, _Grunning, _Gwaiting)
	dropg() // 

	if fn := _g_.m.waitunlockf; fn != nil {
		ok := fn(gp, _g_.m.waitlock)
		_g_.m.waitunlockf = nil
		_g_.m.waitlock = nil
		if !ok {
			if trace.enabled {
				traceGoUnpark(gp, 2)
			}
			casgstatus(gp, _Gwaiting, _Grunnable)
			execute(gp, true) // Schedule it back, never returns.
		}
	}
	schedule()
}
```

park_m 首先把状态切换到waiting，然后调用dropg把它跟m解绑，

然后判断是否需要做unlock操作，如果解锁失败则恢复执行。

如果不需要做unlock，那么调用schedule继续调度。

到现在，我们完成了被动调度，这个G已经被搁置起来了，我们可以去执行其他schedule了。（schedule是永远不返回的，思考下前面的[调度策略](#神奇的调度循环)）

> 笔者第一次看到这里的时候，还有一个疑惑就是这个g没了啊，没有人管它了，那么它怎么恢复呢。
>
> 继续看

### 等待唤醒

所有的`G`在自我'终结'已经完成了后事交代，以`chanrecv`为例,当没有数据的时候，会调用gopark，那么在调用之前它做了什么呢

```go
func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) {
	...
	// No stack splits between assigning elem and enqueuing mysg
	// on gp.waiting where copystack can find it.
	mysg.elem = ep
	mysg.waitlink = nil
	gp.waiting = mysg
	mysg.g = gp
	mysg.isSelect = false
	mysg.c = c
	gp.param = nil
	c.recvq.enqueue(mysg)
	goparkunlock(&c.lock, waitReasonChanReceive, traceEvGoBlockRecv, 3)
	...
}
```

可以看到，gp把自己包装成一个sudog[^4.1]，放进了一个队列里`c.recvq.enqueue(mysg)`，那么这个有什么用呢，我们来以`chansend`为例，看下进程的唤醒。

```go
func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool {
  ...
	if sg := c.recvq.dequeue(); sg != nil {
		// Found a waiting receiver. We pass the value we want to send
		// directly to the receiver, bypassing the channel buffer (if any).
		send(c, sg, ep, func() { unlock(&c.lock) }, 3)
		return true
	}
  ...
}
```

还记得上面我们enqueue了一个sudog吧，那现在队列不为空，直接走send

```go
// send processes a send operation on an empty channel c.
// The value ep sent by the sender is copied to the receiver sg.
// The receiver is then woken up to go on its merry way.
// Channel c must be empty and locked.  send unlocks c with unlockf.
// sg must already be dequeued from c.
// ep must be non-nil and point to the heap or the caller's stack.
func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) {
	... 
	if sg.elem != nil {
		sendDirect(c.elemtype, sg, ep)
		sg.elem = nil
	}
	gp := sg.g // 啊啊哈哈，这个g被取出来了。
	unlockf()
	gp.param = unsafe.Pointer(sg)
	if sg.releasetime != 0 {
		sg.releasetime = cputicks()
	}
	goready(gp, skip+1)
}
```

可见到这里我们已经取得上刚才比较迷惑的g了，那么剩下来的就是怎么把这个调度起来的问题了,这个交给我们个goready

```go
func goready(gp *g, traceskip int) {
	systemstack(func() {
		ready(gp, traceskip, true)
	})
}

// Mark gp ready to run.
func ready(gp *g, traceskip int, next bool) {
	if trace.enabled {
		traceGoUnpark(gp, traceskip)
	}

	status := readgstatus(gp)

	// Mark runnable.
	_g_ := getg()
	mp := acquirem() // disable preemption because it can be holding p in a local var
	if status&^_Gscan != _Gwaiting {
		dumpgstatus(gp)
		throw("bad g->status in ready")
	}

	// status is Gwaiting or Gscanwaiting, make Grunnable and put on runq
	casgstatus(gp, _Gwaiting, _Grunnable)
	runqput(_g_.m.p.ptr(), gp, next) // put
	if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 {
		wakep()
	}
	releasem(mp)
}
```

这里主要做的事情就是

1. 切换到g0栈
2. 把gp切换到runnable
3. 把gp放到待运行队列里，over。且next为true,高优先级！！！
4. 剩下的就交给我们的调度了，gp总会被调度起来的

> 关于runqput暂时不详细分析，它大概的策略就是放到本地队列，如果满了就放到全局队列
>
> ```
> // runqput tries to put g on the local runnable queue.
> // If next is false, runqput adds g to the tail of the runnable queue.
> // If next is true, runqput puts g in the _p_.runnext slot.
> // If the run queue is full, runnext puts g on the global queue.
> // Executed only by the owner P.
> ```

### 可能发生被动调度的地方

按照刚才的理解的话，所有的被动调度都会调用gopark，那我们看下当前的情况。

![image-20200531183142249](http://picgo.vipkk.work/20200531183142.png)

一共有13处，我们依次看下

1. chansend & chanrecv

   这个就是我们刚刚分析的 channel阻塞的时候

2. lock_js.go中的3~7，不懂跳过

3. mgc.go:gcBgMarkWorker

   这个是在gc时候标记准备阶段，stw(如有不对，请拍砖，笔者暂时还没有详细看GC源码)

4. `netpoll.go:netpollblock`

   这是在等待网络io的时候的阻塞，

   > netpoll 是go在epoll基础上封装的网络io库，轻量好用！！！

5. `proc.go:main` pass

6. `proc.go:goparkunlock` 

   一个封装，也是channel重视会用

7. `select.go:block`  & `select.go:selectgo` 

   go select函数阻塞。

### 开始唤醒

我们前面已经把`g`唤醒了，但是一个g要运行还需要`p`和`m`。那么我们开始吧

#### 唤醒空闲的P

```go
    if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 {
        //有空闲的p而且没有正在偷取goroutine的工作线程，则需要唤醒p出来工作
        wakep()
    }
```

在唤醒g之后，如果当前有空闲的g`atomic.Load(&sched.npidle) != 0`,并且没有处于spinning的工作线程的话`atomic.Load(&sched.nmspinning) == 0`，那么就去唤醒p`wakep`来工作。

> Q:为什么需要没有spinning的工作线程
>
> A:因为处于spinning的工作线程本身就在执行偷取工作了，没必要在唤醒一个新的出来了。（这个时候是空余的）

具体的操作由wakep去唤醒

```go
// Tries to add one more P to execute G's.
// Called when a G is made runnable (newproc, ready).
func wakep() {
	// be conservative about spinning threads
	if !atomic.Cas(&sched.nmspinning, 0, 1) {
		return
	}
	startm(nil, true)
}
```

wakep再次确认了是否有spinning线程，如果没有的话就去寻找一个m来工作了。

```go
// Schedules some M to run the p (creates an M if necessary).
// If p==nil, tries to get an idle P, if no idle P's does nothing.
// May run with m.p==nil, so write barriers are not allowed.
// If spinning is set, the caller has incremented nmspinning and startm will
// either decrement nmspinning or set m.spinning in the newly started M.
//go:nowritebarrierrec
func startm(_p_ *p, spinning bool) {
    lock(&sched.lock)
    if _p_ == nil { //没有指定p的话需要从p的空闲队列中获取一个p
        _p_ = pidleget() //从p的空闲队列中获取空闲p
        if _p_ == nil {
            unlock(&sched.lock)
            if spinning {
                // The caller incremented nmspinning, but there are no idle Ps,
                // so it's okay to just undo the increment and give up.
                //spinning为true表示进入这个函数之前已经对sched.nmspinning加了1，需要还原
                if int32(atomic.Xadd(&sched.nmspinning, -1)) < 0 {
                    throw("startm: negative nmspinning")
                }
            }
            return //没有空闲的p，直接返回
        }
    }
    mp := mget() //从m空闲队列中获取正处于睡眠之中的工作线程，所有处于睡眠状态的m都在此队列中
    unlock(&sched.lock)
    if mp == nil {
        //没有处于睡眠状态的工作线程
        var fn func()
        if spinning {
            // The caller incremented nmspinning, so set m.spinning in the new M.
            fn = mspinning
        }
        newm(fn, _p_) //创建新的工作线程
        return
    }
    if mp.spinning {
        throw("startm: m is spinning")
    }
    if mp.nextp != 0 {
        throw("startm: m has p")
    }
    if spinning && !runqempty(_p_) {
        throw("startm: p has runnable gs")
    }
    // The caller incremented nmspinning, so set m.spinning in the new M.
    mp.spinning = spinning
    mp.nextp.set(_p_)
   
    //唤醒处于休眠状态的工作线程
    notewakeup(&mp.park)
}
```

startm用来负责唤醒或创建m，

首先它判断当前有没有空余的p，没有则返回。

然后尝试获取一个m，如果可以获取到，那么就去唤醒他，

如果获取不到，那么就去创建一个。

#### 唤醒M

唤醒是通过`notewakeup`实现的，note我们前面讲过他的封装机制，底层是对os的一些操作。

```go
func notewakeup(n *note) {
    //设置n.key = 1, 被唤醒的线程通过查看该值是否等于1来确定是被其它线程唤醒还是意外从睡眠中苏醒
    old := atomic.Xchg(key32(&n.key), 1)  
    if old != 0 {
        print("notewakeup - double wakeup (", old, ")\n")
        throw("notewakeup - double wakeup")
    }
    //调用futexwakeup唤醒
    futexwakeup(key32(&n.key), 1)
}
```

设置唤醒key,然后调用futexwakeup

```golang
// If any procs are sleeping on addr, wake up at most cnt.
//go:nosplit
func futexwakeup(addr *uint32, cnt uint32) {
    //调用futex函数唤醒工作线程
    ret := futex(unsafe.Pointer(addr), _FUTEX_WAKE_PRIVATE, cnt, nil, nil, 0)
    if ret >= 0 {
        return
    }

    // I don't know that futex wakeup can return
    // EAGAIN or EINTR, but if it does, it would be
    // safe to loop and call futex again.
    systemstack(func() {
        print("futexwakeup addr=", addr, " returned ", ret, "\n")
    })

    *(*int32)(unsafe.Pointer(uintptr(0x1006))) = 0x1006
}
```

对于Linux平台来说，工作线程通过note睡眠其实是通过futex系统调用睡眠在内核之中，所以唤醒处于睡眠状态的线程也需要通过futex系统调用进入内核来唤醒，所以这里的futexwakeup又继续调用包装了futex系统调用的futex函数来实现唤醒睡眠在内核中的工作线程。由 futex 完成最终的调用。



#### 创建M

由`newm`开始

```go
// Create a new m. It will start off with a call to fn, or else the scheduler.
// fn needs to be static and not a heap allocated closure.
// May run with m.p==nil, so write barriers are not allowed.
//go:nowritebarrierrec
func newm(fn func(), _p_ *p) {
    mp := allocm(_p_, fn)
    mp.nextp.set(_p_)
    ......
    newm1(mp)
}
```

newm首先调用allocm函数从堆上分配一个m结构体对象，然后调用newm1函数。

```go
func newm1(mp *m) {
      //省略cgo相关代码.......
      execLock.rlock() // Prevent process clone.
      newosproc(mp)
      execLock.runlock()
}
```

newm1继续调用newosproc函数，newosproc的主要任务是调用clone函数创建一个系统线程，而新建的这个系统线程将从mstart函数开始运行。

```go
// May run with m.p==nil, so write barriers are not allowed.
//go:nowritebarrier
func newosproc(mp *m) {
    stk := unsafe.Pointer(mp.g0.stack.hi)                    
    ......
    ret := clone(cloneFlags, stk, unsafe.Pointer(mp), unsafe.Pointer(mp.g0),         unsafe.Pointer(funcPC(mstart)))
    ......
}

//clone系统调用的Flags选项
cloneFlags = _CLONE_VM | /* share memory */ //指定父子线程共享进程地址空间
  _CLONE_FS | /* share cwd, etc */
  _CLONE_FILES | /* share fd table */
  _CLONE_SIGHAND | /* share sig handler table */
  _CLONE_SYSVSEM | /* share SysV semaphore undo lists (see issue #20763) */
  _CLONE_THREAD /* revisit - okay for now */  //创建子线程而不是子进程
```

clone 可以参考类比fork,由汇编实现，完成工作线程的创建

```assembly
// int32 clone(int32 flags, void *stk, M *mp, G *gp, void (*fn)(void));
TEXT runtime·clone(SB),NOSPLIT,$0
	MOVL	flags+0(FP), DI // 以下4个是系统调用的参数 flags第一个参数，代表创建选项
	MOVQ	stk+8(FP), SI // stk := unsafe.Pointer(mp.g0.stack.hi), 是栈的位置
	MOVQ	$0, DX
	MOVQ	$0, R10

	// Copy mp, gp, fn off parent stack for use by child.
	// Careful: Linux system call clobbers CX and R11.
	MOVQ	mp+16(FP), R8 // M  新创建的M，这个就是要与OS绑定的那个M
	MOVQ	gp+24(FP), R9 // G  M要运行的g,一般是g0
	MOVQ	fn+32(FP), R12 // fn 需要执行的参数

	MOVL	$SYS_clone, AX
	SYSCALL // 执行 clone

	// In parent, return.
	CMPQ	AX, $0 // 父进程 return
	JEQ	3(PC)
	MOVL	AX, ret+40(FP)
	RET

	// In child, on new stack.
	MOVQ	SI, SP // 设置栈顶

	// If g or m are nil, skip Go-related setup.
	CMPQ	R8, $0    // m
	JEQ	nog
	CMPQ	R9, $0    // g
	JEQ	nog

	// Initialize m->procid to Linux tid
	MOVL	$SYS_gettid, AX
	SYSCALL
	MOVQ	AX, m_procid(R8) // 获取pid 并设置到m.procid

	// Set FS to point at m->tls.
	LEAQ	m_tls(R8), DI // 线程的本地存储 DI = M
	CALL	runtime·settls(SB) 

	// In child, set up new stack
	get_tls(CX)
	MOVQ	R8, g_m(R9) // 设置m
	MOVQ	R9, g(CX) // g
	CALL	runtime·stackcheck(SB)

nog:
	// Call fn
	CALL	R12 // fn 此时是mstart

	// It shouldn't return. If it does, exit that thread.
	MOVL	$111, DI
	MOVL	$SYS_exit, AX
	SYSCALL
	JMP	-3(PC)	// keep exiting
```

大概的操作做了注释，有几点需要注意的

1. os做clone操作的时候，寄存器的值也会随之clone一份，所以就有了我们在刚开始，把 g m fn放到寄存器上的操作
2. 为什么需要把g m fn呢，原因在于这几个参数目前还位于父线程的栈之中，而一旦通过系统调用把子线程创建出来之后，子线程将会使用我们在clone系统调用时给它指定的栈。 **栈是新的**



## 2. 抢占调度



# 参考索引

1. [ABA问题](# CAS操作和ABA问题)











[ABA]: https://en.wikipedia.org/wiki/ABA_problem	"ABA问题"



[^4.1]: channel 用来调度g的结构