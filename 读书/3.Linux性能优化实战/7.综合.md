# 一个OOM的问题

> 工作中比较少

## 问题&工具

1. dmesg可以查看OOM信息

   ![image-20200712170242603](http://picgo.vipkk.work/20200712170248.png)

   可以得到

   1. 谁触发的oom
   2. 触发的limit
   3. kill的pid



# 服务器丢包的排查

![img](http://picgo.vipkk.work/20200712171955.png)

## 链路层检查

`netstat -i`

```shell
root@nginx:/# netstat -i
Kernel Interface table
Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
eth0       100       34      0      0 0            10      0      0      0 BMRU
lo       65536        0      0      0 0             0      0      0      0 LRU
```

输出中的 RX-OK、RX-ERR、RX-DRP、RX-OVR ，分别表示接收时的总包数、总错误数、进入 Ring Buffer 后因其他原因（如内存不足）导致的丢包数以及 Ring Buffer 溢出导致的丢包数。



可见此时，链路层没有问题。

## 网络层和传输层

`netstat -s`

```shell

root@nginx:/# netstat -s
Ip:
    Forwarding: 1          //开启转发
    31 total packets received    //总收包数
    0 forwarded            //转发包数
    0 incoming packets discarded  //接收丢包数
    25 incoming packets delivered  //接收的数据包数
    15 requests sent out      //发出的数据包数
Icmp:
    0 ICMP messages received    //收到的ICMP包数
    0 input ICMP message failed    //收到ICMP失败数
    ICMP input histogram:
    0 ICMP messages sent      //ICMP发送数
    0 ICMP messages failed      //ICMP失败数
    ICMP output histogram:
Tcp:
    0 active connection openings  //主动连接数
    0 passive connection openings  //被动连接数
    11 failed connection attempts  //失败连接尝试数
    0 connection resets received  //接收的连接重置数
    0 connections established    //建立连接数
    25 segments received      //已接收报文数
    21 segments sent out      //已发送报文数
    4 segments retransmitted    //重传报文数
    0 bad segments received      //错误报文数
    0 resets sent          //发出的连接重置数
Udp:
    0 packets received
    ...
TcpExt:
    11 resets received for embryonic SYN_RECV sockets  //半连接重置数
    0 packet headers predicted
    TCPTimeouts: 7    //超时数
    TCPSynRetrans: 4  //SYN重传数
  ...
```

> netstat 汇总了IP、ICMP、TCP、UDP等各种协议的收发统计信息。

由上，可以看到，TCP协议发生了丢包和重传

- 11 次连接失败重试（11 failed connection attempts）
- 4 次重传（4 segments retransmitted）
- 11 次半连接重置（11 resets received for embryonic SYN_RECV sockets）
- 4 次 SYN 重传（TCPSynRetrans）
- 7 次超时（TCPTimeouts）

主要是半连接重置，换句话说，主要是握手失败。



### iptables[^1]

> iptables 的原理，它基于 Netfilter 框架，通过一系列的规则，对网络数据包进行过滤（如防火墙）和修改（如 NAT）。

查看filters

![image-20200712173718893](http://picgo.vipkk.work/20200712173718.png)

可见当前对 input 和output都进行了30%的丢包

执行删除

```
root@nginx:/# iptables -t filter -D INPUT -m statistic --mode random --probability 0.30 -j DROP
root@nginx:/# iptables -t filter -D OUTPUT -m statistic --mode random --probability 0.30 -j DROP
```

再次查看

![image-20200712173922107](http://picgo.vipkk.work/20200712173922.png)

验证

```
➜  ~ hping3 -c 10 -S -p 80 hw01
HPING hw01 (eth0 192.168.12.1): S set, 40 headers + 0 data bytes
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=0 win=65535 rtt=1.5 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=1 win=65535 rtt=1.5 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=2 win=65535 rtt=1.5 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=3 win=65535 rtt=1.4 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=4 win=65535 rtt=1.4 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=5 win=65535 rtt=1.4 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=6 win=65535 rtt=1.5 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=7 win=65535 rtt=1.4 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=8 win=65535 rtt=1.4 ms
len=44 ip=192.168.12.1 ttl=63 DF id=0 sport=80 flags=SA seq=9 win=65535 rtt=1.4 ms

--- hw01 hping statistic ---
10 packets transmitted, 10 packets received, 0% packet loss
round-trip min/avg/max = 1.4/1.4/1.5 ms
```

TODO:

验证

![image-20200712174603192](http://picgo.vipkk.work/20200712174603.png)





# 内核线程

Linux在启动的过程中，有三个特殊的进程，也就算PID号最小的三个进程。

- 0号进程为idle进程，这也是系统创建的第一个进程，它再初始化1号和2号进程后，演变为空闲任务。当CPU上没有其他任务执行时，就会运行它。
- 1号进程为init进程，通常为system的进程，在用户态运行，用来管理其他用户态进程
- 2号进程为kthreadd进程，在内核态运行，用来管理内核线程。

所以，要查找内核线程，我们只需要从2号进程开始，查找它的子孙进程即可。

```
➜  ~ ps -f --ppid 2 -p 2
UID        PID  PPID  C STIME TTY          TIME CMD
root         2     0  0 Jun13 ?        00:00:00 [kthreadd]
root         4     2  0 Jun13 ?        00:00:00 [kworker/0:0H]
root         6     2  0 Jun13 ?        00:00:00 [mm_percpu_wq]
root         7     2  0 Jun13 ?        00:05:17 [ksoftirqd/0]
root         8     2  0 Jun13 ?        00:02:04 [rcu_sched]
root         9     2  0 Jun13 ?        00:00:00 [rcu_bh]
root        10     2  0 Jun13 ?        00:00:00 [migration/0]
root        11     2  0 Jun13 ?        00:00:03 [watchdog/0]
root        12     2  0 Jun13 ?        00:00:00 [cpuhp/0]
root        13     2  0 Jun13 ?        00:00:00 [cpuhp/1]
root        14     2  0 Jun13 ?        00:00:03 [watchdog/1]
root        15     2  0 Jun13 ?        00:00:00 [migration/1]
root        16     2  0 Jun13 ?        00:01:07 [ksoftirqd/1]
root        18     2  0 Jun13 ?        00:00:00 [kworker/1:0H]
root        19     2  0 Jun13 ?        00:00:00 [kdevtmpfs]
...
...
...
root     18964     2  0 Jun20 ?        00:00:00 [jbd2/vdb1-8]
root     18965     2  0 Jun20 ?        00:00:00 [ext4-rsv-conver]
root     28192     2  0 16:18 ?        00:00:00 [kworker/1:0]
root     28839     2  0 17:51 ?        00:00:00 [kworker/0:2]
root     28943     2  0 19:25 ?        00:00:00 [kworker/u4:1]
root     28962     2  0 20:02 ?        00:00:00 [kworker/0:0]
root     28963     2  0 20:02 ?        00:00:00 [kworker/1:2]
root     28974     2  0 20:17 ?        00:00:00 [kworker/u4:2]
root     28979     2  0 20:25 ?        00:00:00 [kworker/u4:0]
➜  ~
```

>  之前提过，内核线程有中括号

这里面有几个需要我们重点关注的内核线程

- ksoftirqd：用于软中断，每个CPU都有一个
- kswapd0：用于内存回收。
- kworker：用于执行内核工作队列，分为绑定CPU和未绑定CPU两类
- migration：在负载均衡过程中，把进程迁移到 CPU 上。每个 CPU 都有一个 migration 内核线程。
- jbd2/vdb1-8：jbd 是 Journaling Block Device 的缩写，用来为文件系统提供日志功能，以保证数据的完整性；名称中的 vdb1-8，表示磁盘分区名称和设备号。**每个使用了 ext4 文件系统的磁盘分区，都会有一个 jbd2 内核线程。**
- pdflush：用于将内存中的脏页（被修改过，但还未写入磁盘的文件页）写入磁盘（已经在 3.10 中合并入了 kworker 中）。

我们需要对一些线程有所了解，这样才方便定位问题。



## 火焰图

![img](http://picgo.vipkk.work/20200712204812.png)



- 横轴表示采样数和采样比例。一个函数占用的横轴越宽，就代表它的执行时间越长。同一层的多个函数，则是按照字母来排序。
- 纵轴表示调用栈，由下往上根据调用关系逐个展开。换句话说，上下相邻的两个函数中，下面的函数，是上面函数的父函数。这样，调用栈越深，纵轴就越高。

see more: https://github.com/brendangregg/FlameGraph



# 动态追踪

> 动态追踪技术，通过探针机制，来采集内核或者应用程序的运行信息，从而可以不用修改内核和应用程序的代码，就获得丰富的信息，帮你分析、定位想要排查的问题。

使用 perf 对系统内核线程进行分析时，内核线程依然还在正常运行中，所以这种方法也是动态追踪技术。

> 工作中用不到，todo : https://time.geekbang.org/column/article/86490



# 服务瓶颈分析

> TODO 



思考

这个是有利于工作的，但是目前遇不到这些问题。暂时TODO





[^1]: https://man7.org/linux/man-pages/man8/iptables.8.html