[toc]

---

> 命令工具只是一部分，不是全部。



# 1. 平均负载

> 在开发的时候，每当电脑风扇响起，鼠标不再响应的时候，我就经常会 `命令行->top->kill`三连。

使用top我们可以找到当前负载比较高的进程然后kill。

但是我们也可以使用uptime命令，来观察下平均负载，从而对系统整体有个认知。

```shell
➜  ~ uptime
 1:03  up 5 days, 15:31, 3 users, load averages: 2.08 2.00 2.45
```

uptime前三列输出分别为 当前系统时间、系统运行的持续时间以及登录的用户数。

而后面三个值就是我们系统的平均负载，分别表示过去1分钟、5分钟、15分钟的平均负载。如果我们把平均负载记录，绘制成图的话，笔者的大概这样

<img src="http://picgo.vipkk.work/20200527010649.png" alt="image-20200527010649684" style="zoom:50%;" />

这是过去24小时的平均负载，可以看到大部分在2，然后有几个毛刺甚至到了18。我们直观上可以感觉到越低越好，但是从细节分析，这些平均负载的定义到底是什么呢？ **是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，即平均活跃进程数**

> 可运行状态：是指正在CPU的进程或者正在等待CPU的进程
>
> 下图中的R就是可运行状态 `ps -ux`
>
> ![image-20200527011939035](http://picgo.vipkk.work/20200527011939.png)

>不可中断状态：是指正处于内核态中的进程，并且不可被打断。比如IOwait。
>
>ps中看到的D就是这种，参考[^1]。



如上，如果每个CPU上刚好运行着一个进程，那么这样每个CPU都可以得到充分的利用，这应该是最理想的状态了。(ps. golang GMP 中的P设计的个数限制)

那么回到刚刚的uptime命令，如果平均负载是2的话，意味着什么呢

- 2个CPU的系统上，刚好完全占有
- 4个CPU的系统上，有CPU有50%的空闲
- 1个CPU上，有一半的CPU竞争不到CPU。



既然负载跟CPU个数相关，那么我们应该如何查看CPU的个数呢？可以使用`cat /proc/cpuinfo`中了解机器详细信息，参考[^2]

例如电脑为2核机器，如下图

```shell
➜  ~ # 物理CPU数
➜  ~ cat /proc/cpuinfo| grep "physical id"
physical id	: 0
physical id	: 1
➜  ~ # 查看每个物理 cpu 中 核心数(core 数)：
➜  ~ cat /proc/cpuinfo | grep "cpu cores"
cpu cores	: 1
cpu cores	: 1
➜  ~ # 查看总的逻辑 cpu 数
➜  ~ cat /proc/cpuinfo| grep "processor"
processor	: 0
processor	: 1
➜  ~ # 查看 cpu 型号：
➜  ~ cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c
      2  Intel(R) Xeon(R) Gold 6161 CPU @ 2.20GHz
```



## 平均负载VSCPU使用率

> 在学习博客之前，一直以为负载就CPU使用率

平均负载不仅仅包括CPU使用还有上面提到的D进程。针对IO密集型的服务，我们的CPU使用率并不高，但是平均负载也不低。



## 案例分析[^3]

> 这里主要用到的命令
>
> - stress 
> - mpstat[^6]
> - pidstat[^7]



# 2. CPU上下文切换

> go中我们经常提起轻量级的协程，并会说他在用户态减少了线程调度的消耗包括减少上下文切换等...
>
> 下面我们就来看下cpu中的上下文切换到底都是什么，并且有什么样的消耗。（ps.协程调度也有上下文切换）



> 最近公司因为没有限制goroutine导致CPU飙升，分析这个的原因！！！

## 什么是CPU上下文

简单讲，就是CPU在运行任何任务前，必须依赖的环境，可以称作cpu上下文。

其中包括 CPU上的**寄存器**和**程序计数器**。

![img](http://picgo.vipkk.work/20200528200839.png)

## 上下文切换

> ps. 我自己经常就在疑惑上下文切换的开销，本身寄存器就是最快的存储了，为什么这个开销会大呢。
>
> 因为有这种情况，虽然CPU很快，但是如果进程调度导致缓存冷了，那么io这块也会产生相应的延迟。

所谓上下文切换，就是保存上个任务的状态，恢复下个任务的状态

一般来说会有以下几种任务：**进程上下文切换、线程上下文切换以及中断上下文切换。**

### 进程上下文切换

![img](http://picgo.vipkk.work/20200528203402.png)

进程切换是在内核完成的，通过系统调用陷入内核态，然后再完成切换。

#### 大概耗时

根据 [Tsuna](https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html) 的测试报告，每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。这个时间还是相当可观的，特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是上一节中我们所讲的，导致平均负载升高的一个重要因素。



#### 究竟切换了什么

**明：**

首先明面上我们切换了`内核状态`、`CPU寄存器`、`虚拟内存`。

**暗：**

因为Linux通过TLB[^4] 来管理虚拟内存到物理内存的映射。所以如果缓存冷了，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。



#### 什么时候切换

1. 为了保证公平，Cpu时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样当某个进程时间片耗尽了，就挂起切换。

   > 现在Linux采用的是CFS[^5]算法，完全公平的O(1)调度算法

2. 进程在系统资源不足时，也会被挂起

3. 进程主动调用sleep函数

4. 当高优进程运行时，为了保证高优进程运行，也会挂起切换。

5. 硬件中断（比如io、时钟等）

> 人类的本质是复读机
>
> 仔细想想golang自己的调度算法，似不似莫名相似。



### 线程上下文切换

> 线程是调度的基本单位，而进程则是资源拥有的基本单位

对于同进程中的线程调度，因为内存共享，所以只需要切换线程的私有数据和寄存器就可以。

### 中断上下文切换

跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源



## 案例分析

> 具体实例可参考[^8]

几个关键点



vmstat[^9],可以输出进程切换信息。

关注以下四列

- cs（context switch）是每秒上下文切换的次数。
- in（interrupt）则是每秒中断的次数。
- r（Running or Runnable）是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
- b（Blocked）则是处于不可中断睡眠状态的进程数。



### CS

- cswch : 自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
- nvcswch:非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。

### RES

重调度中断（Rescheduling interrupts），表示 唤醒空闲的CPU俩调度新的任务执行。

可以通过`  cat /proc/interrupts` 得到。示例

<img src="http://picgo.vipkk.work/20200528222232.png" alt="image-20200528222231957" style="zoom:50%;" />



## 总结

上下文切换分析问题

- 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题；
- 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈；
- 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 `/proc/interrupts` 文件来分析具体的中断类型。








[^1]: https://mp.weixin.qq.com/s/E5X9U7QIGnLCd4ETn2Ldlw
[^2]: https://zhuanlan.zhihu.com/p/86855590
[^3]: https://time.geekbang.org/column/article/69618
[^4]: 一种虚拟内存的寻址缓存
[^5]: https://en.wikipedia.org/wiki/Completely_Fair_Scheduler，普通进程、线程是使用 CFS 完全公平调度算法，就是一个红黑树，左边节点小于右边节点的值，运行到目前为止vruntime最小的进程先执行，vruntime 同时考虑了CPU/IO和nice值。这种情况下，没有优先级的概念，完全公平。普通进程、线程是使用 CFS 完全公平调度算法，就是一个红黑树，左边节点小于右边节点的值，运行到目前为止vruntime最小的进程先执行，vruntime 同时考虑了CPU/IO和nice值。这种情况下，没有优先级的概念，完全公平。
[^6]: https://www.man7.org/linux/man-pages/man1/mpstat.1.html
[^7]: pidstat:  https://www.man7.org/linux/man-pages/man1/pidstat.1.html
[^8]: https://time.geekbang.org/column/article/70077
[^9]: vmstat: https://www.man7.org/linux/man-pages/man8/vmstat.8.html